# -*- coding: utf-8 -*-
"""Drone_Detector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1906yptEBb6-YDYSCkJZq1WnKm247NooY

#1. Data Preprocessing

##1-1. Data Load
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import librosa
import scipy.signal
import matplotlib.pyplot as plt
import csv
import pandas as pd
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import Dataset
import torchaudio

# %matplotlib inline

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

csv_path = '/home/stealthdrone/Desktop/csv/Trimmed_audio_balanced_ts_1.csv' 
file_path = '/home/stealthdrone/Desktop/dataset/Trimmed_audio_balanced_ts_1'

csv_path_2 = '/home/stealthdrone/Desktop/csv/Trimmed_audio_test_2.csv'
file_path_2 = '/home/stealthdrone/Desktop/dataset/Trimmed_audio_test_2'

SR = 44100

train_batch = 64
val_batch = 64
test_batch = 16

metaData = pd.read_csv(csv_path)
print(metaData.iloc[0, :])
metaData

"""#Output will be a 0.5 sec mfcc"""

def preemphasis(y, coef=0.97, zi=None, return_zf=False):

    b = np.asarray([1.0, -coef], dtype=y.dtype)
    a = np.asarray([1.0], dtype=y.dtype)

    if zi is None:
        zi = scipy.signal.lfilter_zi(b, a)

    y_out, z_f = scipy.signal.lfilter(b, a, y,
                                      zi=np.asarray(zi, dtype=y.dtype))

    if return_zf:
        return y_out, z_f

    return y_out

class DroneSoundDataset(Dataset):
    def __init__(self, csv_path, file_path, folderList):
        metaData = pd.read_csv(csv_path)
        self.file_names = []
        self.labels = []
        self.folders = []


        for i in range(0, len(metaData)):
            if metaData.iloc[i, 2] in folderList:
                self.file_names.append(metaData.iloc[i, 0])
                self.labels.append(metaData.iloc[i, 1])
                self.folders.append(metaData.iloc[i, 2])
          
        self.file_path = file_path
        #Streo type to Mono
        #self.mixer = torchaudio.transforms.DownmixMono()
        self.folderList = folderList
      
    def __getitem__(self, index):
        
        path = self.file_path + '/' + self.file_names[index] + '.wav'
        data = librosa.core.load(path, sr = SR, mono = True)[0]

        #pre-emphasis

        data = preemphasis(data)
        #sound = [y, sr]
        #sr = 44.1 kHz
        
        mfcc = librosa.feature.mfcc(y = data, sr = SR, hop_length = 1024,
                            n_mfcc = 40)

        # 0.5 sec * 44.1kHz -> mfcc spectrogram

        # 44.1k to 16k downsampling??
        #고려해야 하는 게, audio duration * sr = num of samples
        soundFormatted = torch.zeros([40, 44]).type(torch.FloatTensor)
        soundFormatted = torch.from_numpy(mfcc).float()

        return soundFormatted, self.labels[index]
  
    def __len__(self):
        return len(self.file_names)

train_set = DroneSoundDataset(csv_path, file_path, [0])
val_set = DroneSoundDataset(csv_path, file_path, [1])
test_set = DroneSoundDataset(csv_path_2, file_path_2, range(0,2))

print("Train set size: " + str(len(train_set)))
print("Validation set size: " + str(len(val_set)))
print("Test set size: " + str(len(test_set)))

kwargs = {'num_workers': 2, 'pin_memory': True} if device == 'cuda' else {} #needed for using datasets on gpu

train_loader = torch.utils.data.DataLoader(train_set, batch_size = train_batch, shuffle = True, **kwargs)
val_loader = torch.utils.data.DataLoader(val_set, batch_size = val_batch, shuffle = True, **kwargs)
test_loader = torch.utils.data.DataLoader(test_set, batch_size = test_batch, shuffle = True, **kwargs)

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv1d(44, 64, 3, padding=1)    # 40 x 44 -> 40 x 64
        self.dropout1 = nn.Dropout(p=0.2)
        self.bn1 = nn.BatchNorm1d(64)
        self.pool1 = nn.MaxPool1d(2)                    # 40 x 64 -> 20 x 64
        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)   # 20 x 64 -> 20 x 128
        self.bn2 = nn.BatchNorm1d(128)
        self.pool2 = nn.MaxPool1d(2)                    # 20 x 128 -> 10 x 128
        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)  # 10 x 128 -> 10 x 256
        self.bn3 = nn.BatchNorm1d(256)
        self.pool3 = nn.MaxPool1d(2)                    # 10 x 256 -> 5 x 256
        self.conv4 = nn.Conv1d(256, 512, 3, padding=1)  # 5 x 256 -> 5 x 512
        self.bn4 = nn.BatchNorm1d(512)
        self.pool4 = nn.AvgPool1d(5)                    # 5 x 512 -> 1 x 512
        self.fc1 = nn.Linear(512, 64)
        self.dropout2 = nn.Dropout(p=0.5)
        self.fc2 = nn.Linear(64, 6)
        
    def forward(self, x):
        #print(x.size())      
        x = self.conv1(x)
        #print(x.size())
        x = F.relu(self.bn1(x))
        #print(x.size())
        x = self.pool1(x)
        x = self.dropout1(x)
        #----------------------------#


        #print(x.size())
        x = self.conv2(x)
        #print(x.size())
        x = F.relu(self.bn2(x))
        #print(x.size())
        x = self.pool2(x)
        #print(x.size())
        x = self.dropout1(x)
        #----------------------------#


        x = self.conv3(x)
        #print(x.size())
        x = F.relu(self.bn3(x))
        #print(x.size())
        x = self.pool3(x)
        #print(x.size())
        x = self.dropout1(x)
        #----------------------------#


        x = self.conv4(x)
        #print(x.size())
        x = F.relu(self.bn4(x))
        #print(x.size())
        x = self.pool4(x)
        x = self.dropout1(x)
        #----------------------------#
        
        # x = self.avgPool(x)
        #print(x.size())
        x = x.view(-1, 512 * 1)
        # x = x.permute(0, 2, 1)
        #print(x.size()) #change the 512x1 to 1x512
        x = F.relu(self.fc1(x))
        #x = self.dropout2(x)
        #----------------------------#


        #print(x.size())
        x = self.fc2(x)
        #----------------------------#

        #print(x.size())
        x = F.log_softmax(x, dim=1)
        #print(x.size())
        return x


model = Net()
model.to(device)
print(model)

optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.0001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.1)

def train(model, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        optimizer.zero_grad()

        # For test
        data.transpose_(1, 2)
        #print(data.size())

        model = model.double()
        data = torch.as_tensor(data, dtype=torch.double, device=device)
        #print("Data type", type(data))
        target = torch.as_tensor(target, dtype=torch.long, device=device)

        data = data.to(device)
        target = target.to(device)
        data = data.requires_grad_() #set requires_grad to True for training
        
        #print(f"data size: {data.size()}")
        output = model(data)
        #output = output.permute(1, 0, 2) #original output dimensions are batchSize x 1 x 6  
                                         #it is converted into 1 x batchsize x 6
        #print(f"output size: {output.size()}, target: {target.size()}")
        loss = F.nll_loss(output, target) #the loss functions expects a batchSizex6 input
        
        loss.backward()
        optimizer.step()
        
        if batch_idx % log_interval == 0: #print training stats
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss))
            f.write('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}\n'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss))

def validation(model, epoch):
    model.eval()
    correct = 0
    
    for data, target in val_loader:
        data.transpose_(1, 2)
        model = model.double()
        data = torch.as_tensor(data, dtype=torch.double, device=device)
        target = torch.as_tensor(target, dtype=torch.long, device=device)

        data = data.to(device)
        target = target.to(device)
        output = model(data)
        #output = output.permute(1, 0, 2)
        pred = output.max(1)[1] # get the index of the max log-probability
        correct += pred.eq(target).cpu().sum().item()
    
    print('\nValidation set: Accuracy: {}/{} ({:.0f}%)\n'.format(
        correct, len(val_loader.dataset),
        100. * correct / len(val_loader.dataset)))
    
    f.write('\nValidation set: Accuracy: {}/{} ({:.0f}%)\n'.format(
        correct, len(val_loader.dataset),
        100. * correct / len(val_loader.dataset)))

import datetime
time = str(datetime.datetime.now()).split(".")[0]
f = open("/home/stealthdrone/Desktop/output_log/"+ time + "_output.txt", "w")

f.write("Start: {}\n".format(datetime.datetime.now()))
print("Start: {}".format(datetime.datetime.now()))

log_interval = 20
for epoch in range(1, 40):
    if epoch == 31:
        print("First round of training complete. Setting learn rate to 0.001.")
    
    train(model, epoch)
    scheduler.step()
    validation(model, epoch)

#Test

#코드 짜는 중

correct = 0
total = 0
with torch.no_grad():
    for data, labels in test_loader:

        data.transpose_(1,2)
        model = model.double()
        data = torch.as_tensor(data, dtype=torch.double, device=device)
        labels = torch.as_tensor(labels, dtype=torch.long, device=device)

        outputs = model(data)
        pred = outputs.max(1)[1]

        total += labels.size(0)
        correct += (pred == labels).sum().item()

print('Accuracy of the network on the %d test wav file: %d %%\n' % (len(test_set),100 * correct / total))
f.write('Accuracy of the network on the %d test wav file: %d %%\n' % (len(test_set), 100 * correct / total))

classes = ['section 1 forward', 'section 1 hovering', 
           'section 2 forward', 'section 2 hovering',
           'section 3 forward', 'section 3 hovering']
           
class_correct = list(0. for i in range(6))
class_total = list(0. for i in range(6))

count = 0
f.write("TEST Start: {}\n".format(datetime.datetime.now()))
print("TEST Start: {}\n".format(datetime.datetime.now()))

with torch.no_grad(): #It means it's not gonna train for this model with dataset
    for data, labels in test_loader:
        
        count += 1
        if count == int(len(test_set) / test_batch):
            break

        data.transpose_(1, 2)

        model = model.double()
        data = torch.as_tensor(data, dtype=torch.double, device=device)
        labels = torch.as_tensor(labels, dtype=torch.long, device=device)
        

        #print("labels.size()", count, labels.size())
        
        outputs = model(data)
        pred = outputs.max(1)[1]

        c = (pred == labels).squeeze()
        #print("c.size", c.size())
        #print("labels.size", labels.size())
        
        
        for i in range(4): #batch_size = 4
            label = labels[i]
            #print("label", label)
            class_correct[label] += c[i].item()
            class_total[label] += 1
            #print("class_correct", class_correct)
            #print("class_total", class_total)

    f.write("TEST END: {}\n".format(datetime.datetime.now()))
    print("TEST END: {}".format(datetime.datetime.now()))
for i in range(6):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))
    f.write('Accuracy of %5s : %2d %%\n' % (
        classes[i], 100 * class_correct[i] / class_total[i]))

f.write("End: {}\n".format(datetime.datetime.now()))
print("End: {}".format(datetime.datetime.now()))

f.close()

def audio_norm(data):
    max_data = np.max(data)
    min_data = np.min(data)
    data = (data-min_data)/(max_data-min_data+1e-6)
    return data-0.5

"""##1-3. MFCC
* Mask part of spectrograms if more data is needed to train the model

##1-4. Label and Reshape

#2. CNN

##2-1. Model Architecture

##2-2. Model Visualization and Summary

##2-3. Optimizer

##2-4. Training
"""
